{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "This pipeline verifies the validity, accuracy and effectiveness of the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet Files in the directory:\n",
      "\n",
      "cleaned_2021_ch4.parquet\n",
      "cleaned_2021_co2.parquet\n",
      "cleaned_2021_n2o.parquet\n",
      "cleaned_2021_co2e_100yr.parquet\n",
      "cleaned_2022_ch4.parquet\n",
      "cleaned_2022_co2.parquet\n",
      "cleaned_2022_n2o.parquet\n",
      "cleaned_2022_co2e_100yr.parquet\n",
      "cleaned_2023_ch4.parquet\n",
      "cleaned_2023_co2.parquet\n",
      "cleaned_2023_n2o.parquet\n",
      "cleaned_2023_co2e_100yr.parquet\n",
      "cleaned_2024_ch4.parquet\n",
      "cleaned_2024_co2.parquet\n",
      "cleaned_2024_n2o.parquet\n",
      "cleaned_2024_co2e_100yr.parquet\n",
      "Parquet file loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "\n",
    "parquet_files = {\n",
    "    \"cleaned_2021_ch4.parquet\" : 2021,\n",
    "    \"cleaned_2021_co2.parquet\" : 2021,\n",
    "    \"cleaned_2021_n2o.parquet\" : 2021,\n",
    "    \"cleaned_2021_co2e_100yr.parquet\" : 2021,\n",
    "    \"cleaned_2022_ch4.parquet\" : 2022,\n",
    "    \"cleaned_2022_co2.parquet\" : 2022,\n",
    "    \"cleaned_2022_n2o.parquet\" : 2022,\n",
    "    \"cleaned_2022_co2e_100yr.parquet\" : 2022,\n",
    "    \"cleaned_2023_ch4.parquet\" : 2023,\n",
    "    \"cleaned_2023_co2.parquet\" : 2023,\n",
    "    \"cleaned_2023_n2o.parquet\" : 2023,\n",
    "    \"cleaned_2023_co2e_100yr.parquet\" : 2023,\n",
    "    \"cleaned_2024_ch4.parquet\" : 2024,\n",
    "    \"cleaned_2024_co2.parquet\" : 2024,\n",
    "    \"cleaned_2024_n2o.parquet\" : 2024,\n",
    "    \"cleaned_2024_co2e_100yr.parquet\" : 2024\n",
    "}\n",
    "print(\"Parquet Files in the directory:\\n\")\n",
    "for each in parquet_files:\n",
    "    print(each)\n",
    "\n",
    "target_parquet = input(\"Enter the target parquet file name to upload: \")\n",
    "df = None\n",
    "\n",
    "if target_parquet in parquet_files:\n",
    "    parquet_file = f\"../cleaned_data/{parquet_files[target_parquet]}/{target_parquet}\"\n",
    "    df = dd.read_parquet(parquet_file, npartitions=10)\n",
    "    print(\"Parquet file loaded successfully.\")\n",
    "else:\n",
    "    print(\"Invalid input. Please enter a valid parquet file name.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id                               int64\n",
       "gas                                  category\n",
       "emissions_quantity_ton                float64\n",
       "emissions_factor_ton                  float64\n",
       "capacity_ha                           float64\n",
       "capacity_factor                       float64\n",
       "activity_ha                           float64\n",
       "sector                               category\n",
       "subsector                            category\n",
       "country_name                         category\n",
       "country_code                         category\n",
       "latitude                              float64\n",
       "longitude                             float64\n",
       "year                                    int64\n",
       "quarter                                 int32\n",
       "month                                   int32\n",
       "start_date                datetime64[us, UTC]\n",
       "end_date                  datetime64[us, UTC]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Schema validation\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask Series Structure:\n",
      "npartitions=1\n",
      "activity_ha    int64\n",
      "year             ...\n",
      "Dask Name: sum, 4 expressions\n",
      "Expr=(~ NotNull(frame=ReadParquetFSSpec(f1fc9b7))).sum()\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "print(df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
